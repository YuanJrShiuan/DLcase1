{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1.** We want to build a 1-hidden-layer neural network for two-classification problem. Implement the layer_size() function to define the size of each layer.\n",
    "<br />\n",
    "**Hint:**\n",
    "1. The network has one input layer, one hidden layer and one output layer\n",
    "2. Size of input layer= size of each sample; size of hidden layer (up to you); size of output layer = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_size(X,Y,hidden_size):\n",
    "    '''\n",
    "    X: input dataset (shape: n*m_samples) ！不一定为方阵 ！\n",
    "    Y : groud truth vector (1*n_samples)\n",
    "    '''\n",
    "    ###input size\n",
    "    input_s= np.shape(X)[1]\n",
    "    ###hidden size \n",
    "    hidden_s= hidden_size\n",
    "    ###output size\n",
    "    output_s= 1\n",
    "    \n",
    "    return input_s,hidden_s,output_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 2.** Implement initialize() to initialize parameters in neural networks by using np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(input_s,hidden_s,output_s):\n",
    "    '''\n",
    "    we need to initialize two sets of parameters:\n",
    "    W1 -- weight matrix of shape (hidden_s, input_s)\n",
    "    b1 -- bias vector of shape (hidden_s, 1)\n",
    "    W2 -- weight matrix of shape (output_s, hidden_s)\n",
    "    b2 -- bias vector of shape (output_s, 1)\n",
    "    '''\n",
    "    W1 = np.random.uniform(0,1,(hidden_s,input_s))\n",
    "    b1 = np.random.uniform(0,1,(hidden_s,1))\n",
    "    W2 = np.random.uniform(0,1,(output_s, hidden_s))\n",
    "    b2 = np.random.uniform(0,1)\n",
    "    \n",
    "    params = {'W1':W1,'b1':b1,'W2':W2,'b2':b2}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 3.** Implement forward()\n",
    "<br >\n",
    "**Hint:**\n",
    "1. Given X and params\n",
    "2. Calculate $H1=W1X+b1$; $A1=tanh(H1)$\n",
    "3. Caculate $H2=W2A1+b2$;$A2=sigmoid(H2)$\n",
    "4. Store H1,H2,A1,A2 in a dictionary and return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,params):\n",
    "    ###set parametes\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    ###calculate H1,A1\n",
    "    ###your code\n",
    "    H1 = np.dot(W1,X.T) + b1  # shape(n,n)\n",
    "    A1 = np.tanh(H1) \n",
    "    ###calculate H2,A2\n",
    "    ###your code\n",
    "    H2 = np.dot(W2,A1) + b2 # shape(1,n)\n",
    "    A2 = sigmoid(H2)\n",
    "    ### store in dictionary\n",
    "    out={'H1':H1,'A1':A1,'H2':H2,'A2':A2}\n",
    "    \n",
    "    \n",
    "    return out\n",
    "\n",
    "def sigmoid(x): # wrap a function to compute sigmoid\n",
    "    return np.exp(x) / (1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 4.** Implement backward()\n",
    "1. The cost function is the same as logistic cost function in assignment 2\n",
    "2. Calculate the gradients of W1,b1,W2,b2 \n",
    "3. Store the gradients in a dictionary and return it\n",
    "4. Avoid using 'for' when calculate the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(params,out,X,Y):\n",
    "    '''\n",
    "    calculate cost\n",
    "    calculate gradients:\n",
    "    dW1-- gradient of W1\n",
    "    db1-- gradient of b1\n",
    "    dW2-- gradient of b2\n",
    "    db2-- gradient of b2\n",
    "    \n",
    "    '''\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    H1 = out['H1']\n",
    "    A1 = out['A1']\n",
    "    H2 = out['H2']\n",
    "    A2 = out['A2']\n",
    "    m = X.shape[1]\n",
    "    ###calculate cost\n",
    "    cost = (-1/m)*np.sum(Y * np.log(A2+1e-5) + (1 - Y) * (np.log(1-A2+1e-5))) # 提高浮点精度可以避免数字过小造成\n",
    "                                                                              # 的溢出，并保证cost值存在\n",
    "    \n",
    "    ###calculate grad\n",
    "    dH2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dH2,A1.T) #要除以m的原因是，这里参数矩阵中的每一个参数都是m个样本对这个参数的影响之和\n",
    "    db2 = (1/m) * np.sum(dH2,axis=1,keepdims=True)\n",
    "    dH1 = np.multiply(np.dot(W2.T,dH2),1-np.power(A1,2))\n",
    "    dW1 = (1/m) * np.dot(dH1,X)\n",
    "    db1 = (1/m) * np.sum(dH1,axis=1,keepdims=True)\n",
    "    ###store in dictionary\n",
    "    grads = {'dW1':dW1,'db1':db1,'dW2':dW2,'db2':db2}\n",
    "    return cost,grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 5.** Implement optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(params,grads,learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    update parameters and return them\n",
    "    W1=W1-learning_rate*dw1\n",
    "    \"\"\"\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    W1 = W1 - learning_rate*grads['dW1']\n",
    "    W2 = W2 - learning_rate*grads['dW2']\n",
    "    b1 = b1 - learning_rate*grads['db1']\n",
    "    b2 = b2 - learning_rate*grads['db2']\n",
    "    params = {'W1':W1,'b1':b1,'W2':W2,'b2':b2}\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 6.** Merge all the above functions into a model, implement model() function\n",
    "1. Define the size of each layer\n",
    "2. Initialze parameters\n",
    "3. Forward propogation\n",
    "4. Backward propogation\n",
    "5. Update parameters\n",
    "6. Return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y,hidden_size,learning_rate,num_iterations):\n",
    "    input_s,hidden_s,output_s = layer_size(X,Y,hidden_size)\n",
    "    params = initialize(input_s,hidden_s,output_s)\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        out = forward(X,params)\n",
    "        cost,grads = backward(params,out,X,Y)\n",
    "        if cost != np.nan:\n",
    "            costs.append(cost)\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Cost after iteration \",i,\"cost:\",cost)\n",
    "        if (abs(cost - costs[i-1]) <= 0.00001 and i > 0) or np.sum(costs == np.nan) >=50:\n",
    "            # When testing the code, some cost kept nan 'cause the optimal solution had been reached \n",
    "            # or learning rate is too high, so add this breaking condition.\n",
    "            if cost == np.nan:\n",
    "                print(\"Cost turns to none!\")\n",
    "            break\n",
    "        params = optimize(params,grads,learning_rate)\n",
    "    return params,costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**problem 7.** Implement predict() to predict the label.\n",
    "<br />\n",
    "**Hint:**\n",
    "1. Use the learned params to calculate $A2$.\n",
    "2. Convert the entries of $A2$ into 0 (if $A2$ <= 0.5) or 1 (if $A2$ > 0.5).\n",
    "3. Store the results in pred\\_Y and return it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(params,X):\n",
    "    \"\"\"\n",
    "    return the predicted label of each sample\n",
    "    \"\"\"\n",
    "    ###set parametes\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    ###calculate H1,A1\n",
    "    ###your code\n",
    "    H1 = np.dot(W1,X.T) + b1  # shape(n,n)\n",
    "    A1 = np.tanh(H1) \n",
    "    ###calculate H2,A2\n",
    "    ###your code\n",
    "    H2 = np.dot(W2,A1) + b2 # shape(1,n)\n",
    "    A2 = sigmoid(H2)\n",
    "    ### pred_Y\n",
    "    pred_Y = np.zeros(A2.shape)\n",
    "    pred_Y[A2>0.5] = 1\n",
    "    return pred_Y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 8.** \n",
    "1. Use the same dataset in assignment1 \n",
    "2. Implement train_test_split() to split the dataset into training and test (remember Standardization). \n",
    "3. Use model() and training set to train a neural network.\n",
    "4. Calculate accuracy in both training and test.\n",
    "5. Test different values of learning rate. plot costs to compare their performance. \n",
    "6. Compare the performance of neural network to logistic regression(assignment 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-bcbe25dd0e97>:21: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (-1/m)*np.sum(Y * np.log(A2) + (1 - Y) * (np.log(1-A2)))\n",
      "<ipython-input-70-bcbe25dd0e97>:21: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = (-1/m)*np.sum(Y * np.log(A2) + (1 - Y) * (np.log(1-A2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration  0 cost: nan\n",
      "Cost after iteration  1000 cost: 0.15113639600593148\n",
      "train_accuracy= 0.9974874371859297\n",
      "test_accuracy= 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "def train_test_split(X,Y,ratio):\n",
    "    train_x = X[:int(X.shape[0]*ratio),:]\n",
    "    test_x = X[int(X.shape[0]*ratio):,:]\n",
    "    train_y = Y[:int(X.shape[0]*ratio)]\n",
    "    test_y = Y[int(X.shape[0]*ratio):]\n",
    "    \n",
    "    return train_x,train_y,test_x,test_y\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "Y = cancer.target\n",
    "train_x,train_y,test_x,test_y = train_test_split(X,Y,0.7)\n",
    "train_x,test_x = standardization(train_x),standardization(test_x)\n",
    "num = 10000\n",
    "params,costs = model(train_x,train_y,int(X.shape[0]/2),0.05,num)\n",
    "pred_train_Y = predict(params,train_x)\n",
    "pred_test_Y = predict(params,test_x)\n",
    "train_accuracy = np.mean(pred_train_Y == train_y)\n",
    "test_accuracy = np.mean(pred_test_Y == test_y)\n",
    "print('train_accuracy=',train_accuracy)\n",
    "print('test_accuracy=',test_accuracy)\n",
    "###use different learning rate and plot the costs\n",
    "###your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration  0 cost: 136.34748961619687\n",
      "Cost after iteration  1000 cost: 1.020232280869435\n",
      "Cost after iteration  2000 cost: 0.6014346541996872\n",
      "Cost after iteration  3000 cost: 0.5155658229295599\n",
      "Cost after iteration  4000 cost: 0.4556364238375961\n",
      "Cost after iteration  5000 cost: 0.33297687678286125\n",
      "Cost after iteration  6000 cost: 0.2789697790952401\n",
      "Cost after iteration  7000 cost: 0.2377675382751478\n",
      "Cost after iteration  8000 cost: 0.20626622695318092\n",
      "Cost after iteration  9000 cost: 0.18265603501083452\n",
      "Cost after iteration  0 cost: 135.77881951015922\n",
      "Cost after iteration  1000 cost: 0.5964837056290326\n",
      "Cost after iteration  2000 cost: 0.46423278340882534\n",
      "Cost after iteration  3000 cost: 0.3917309880090234\n",
      "Cost after iteration  4000 cost: 0.33035823138577286\n",
      "Cost after iteration  5000 cost: 0.2903233361694015\n",
      "Cost after iteration  6000 cost: 0.268200459890605\n",
      "Cost after iteration  7000 cost: 0.25414019807996346\n",
      "Cost after iteration  0 cost: 136.01574929202565\n",
      "Cost after iteration  1000 cost: 0.2775498035509435\n",
      "Cost after iteration  2000 cost: 0.23258972802232544\n",
      "Cost after iteration  3000 cost: 0.08364512232034038\n",
      "Cost after iteration  4000 cost: 0.033704559787171046\n",
      "Cost after iteration  0 cost: 135.9471149926349\n",
      "Cost after iteration  1000 cost: 0.0150662078446318\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rates = [0.005,0.01,0.05,0.1]\n",
    "costls = []\n",
    "num = 10000\n",
    "for rate in rates:\n",
    "    params,costs = model(train_x,train_y,int(X.shape[0]/2),rate,num)\n",
    "    costls.append(costs[-1])\n",
    "plt.plot(rates,costls,linewidth = 3,color = 'r',marker = 'o',markerfacecolor='pink',markersize=10)\n",
    "plt.show()\n",
    "# According to the result, the cost is none when rate is more than 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
